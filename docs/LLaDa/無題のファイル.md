## **1. Bối cảnh**

- Trước năm 2025, đại đa số **Large Language Models (LLMs)** dựa trên **mô hình tự hồi quy (Autoregressive Models – ARMs)**, tức dự đoán từng token một theo thứ tự từ trái sang phải. Phương pháp này vốn rất hiệu quả nhưng cũng có **hạn chế** như:
    - Phụ thuộc vào thứ tự token.
    - Tốn thời gian sinh chuỗi dài do lần lượt từng token.
    - Khó khăn với các nhiệm vụ yêu cầu hiểu ngữ cảnh “ngược”, như _reversal reasoning_. [9030club.github.io+1](https://9030club.github.io/papers/papers/2502.09992v2/index.html?utm_source=chatgpt.com)
- **LLaDA** được đề xuất để tìm một **phương pháp thay thế nguyên lý hơn tự hồi quy**,sử dụng **diffusion models** – vốn đã thành công lớn trong sinh ảnh – cho nhiệm vụ sinh ngôn ngữ văn bản.


## **2. Định nghĩa**

Theo tác giả, thì **LLaDA (Large Language Diffusion with mAsking)** – một kiến trúc LLM mới dựa trên **diffusion model** thay vì tự hồi quy.
Về nguyên lí:
 - Dữ liệu đầu vào được xử lý bằng một **quy trình mask ngẫu nhiên (forward masking)**.
 - Mô hình học cách **phục hồi (reverse) các token đã bị che** dựa trên bối cảnh còn lại, bằng **Transformer tiêu chuẩn**.
Khác với mô hình tự hồi quy, LLaDA:
- Dự đoán **song song tất cả token bị mask**, không phải lần lượt từng token.
- Học cả **mối quan hệ hai chiều** trong câu.

## **3. Mục tiêu**

Mục tiêu chính của LLaDA là:
1. **Khởi tạo một phương pháp tổng quát và nguyên lý** cho mô hình ngôn ngữ không dựa vào tự hồi quy, mà dựa trên **generative modeling**. 

2. **Xây dựng mô hình lớn thực sự (scalable)** với khả năng cạnh tranh với các mô hình ARM hiện đại (ví dụ LLaMA3 8B). 

3. **Giải quyết một số hạn chế nội tại của mô hình ARM**, ví dụ như _reversal curse_, bằng khả năng xử lý mối quan hệ ngôn ngữ “toàn phần” (bidirectional). 

4. **Cho phép in-context learning và instruction following** một cách tự nhiên thông qua cơ chế phủ mask và phục hồi thống kê.




$$q_{t|0}(x_t^i|x_0^i) = \begin{cases} 1-t, & \text{if } x_t^i = x_0^i \text{ (unchanged)} \ t, & \text{if } x_t^i = \mathbf{M} \text{ (masked)} \end{cases}$$
